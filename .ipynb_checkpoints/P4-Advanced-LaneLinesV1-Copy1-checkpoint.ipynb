{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Import all essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "print(\"Step 1 Complete - All Libraries Imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Setup for Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Termination criteria used \n",
    "# Reference: http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "fig, axs = plt.subplots(5,4, figsize=(16, 11))\n",
    "fig.subplots_adjust(hspace = .2, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners - The tweak here is to use the chess board corners as (9, 6) instead of (8, 6) in lessons\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    \n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        # Improve accuracy of corners Reference: http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "        accurate_corners = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(accurate_corners)\n",
    "\n",
    "        # Draw and display the corners. Adjust drawing of chessboard corners to (9,6)\n",
    "        cv2.drawChessboardCorners(img, (9,6), accurate_corners, ret)\n",
    "        axs[idx].axis('off')\n",
    "        axs[idx].imshow(img)\n",
    "#         cv2.imshow('img',img) #Does not work\n",
    "#         write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "#         cv2.imwrite(write_name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Find Camera Matrix, Distortion Co-efficients and Test Undistortion on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The technique learnt in the lesson have been applied to all images\n",
    "# Initialize pickle dictionary - Use for pickle dump\n",
    "dist_pickle = {}\n",
    "for idx, fname in enumerate(images):\n",
    "    # Read each image to undistort\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    #Identify the dimensions\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    \n",
    "    #Calibrate camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    \n",
    "    #Undistort images\n",
    "    #Step 1- Get Optimal New Camera Matrix\n",
    "    h, w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    #dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    #Step 2a- Undistort image shortest path\n",
    "    #dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    \n",
    "    #Step 2b - Undistort image curved path\n",
    "    mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "    dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "        \n",
    "    # Step 3b - Crop image \n",
    "    x,y,w,h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "#     cv2.imwrite('calibresult.png',dst)\n",
    "    \n",
    "    #Create a dictionary to dump undistorted image data into a pickle file\n",
    "#     dist_pickle[\"mtx\"] = mtx\n",
    "#     dist_pickle[\"dist\"] = dist\n",
    "    # Correct Functionality for Pickle Dump\n",
    "    dist_pickle[fname] = mtx\n",
    "    dist_pickle[fname+\"_dist\"] = dist\n",
    "    #dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "\n",
    "#Dump all undistorted images into a pickle file\n",
    "pickle.dump(dist_pickle, open( \"calibration.p\", \"wb\" ))\n",
    "\n",
    "# Pickle single image calibration for testing purposes\n",
    "# Test undistortion on an image from Camera Calibration Images folder\n",
    "img = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "# Undistort image - without Optimal new camera matrix\n",
    "# dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "# Undistort image - with Optimal new camera matrix\n",
    "# dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# cv2.imwrite('./camera_cal/calibration1_undist.jpg',dst)\n",
    "\n",
    "#Step 2b - Undistort image curved path\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"calibration1.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Applying Undistortion To Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using Undistort approach for curved path instead of shortest path.\n",
    "# Reference: http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html\n",
    "def undistort_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "    mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "    dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "    x,y,w,h = roi\n",
    "    undist_img = dst[y:y+h, x:x+w]\n",
    "    return undist_img\n",
    "\n",
    "# Using Undistort approach for shortest path\n",
    "def undistort(img):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "test_images = glob.glob('./test_images/*.jpg')\n",
    "for idx, fname in enumerate(test_images):\n",
    "    test_image = cv2.imread(fname)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    #undist_image = undistort_image(test_image)\n",
    "    undist_image = undistort(test_image)\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(test_image)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(undist_image)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    #Saving Undistorted Images for next step of processing\n",
    "    cv2.imwrite('./output_images/test'+str(idx)+'_undist.jpg',undist_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Applying Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unwarp(img, src, dst):\n",
    "    h,w = img.shape[:2]\n",
    "    # use cv2.getPerspectiveTransform() to get M, the transform matrix, and Minv, the inverse\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    # use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, (w,h), flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv\n",
    "\n",
    "def warp_image(img, src, dst):\n",
    "    # Compute and apply perpective transform\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #h, w = img.shape[:2]\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)  # keep same size as input image    \n",
    "    #warped = cv2.warpPerspective(img, M, (h, w), flags=cv2.INTER_LINEAR)  # keep same size as input image    \n",
    "    return warped, M, Minv\n",
    "\n",
    "def find_polygon(xsize, ysize):\n",
    "    point1 = (int(xsize*0.11),int(ysize))\n",
    "    #print(point1)\n",
    "    point2 = (int(xsize*0.44),int(ysize*0.60))\n",
    "    #print(point2)\n",
    "    point3 = (int(xsize*0.57),int(ysize*0.60))\n",
    "    #print(point3)\n",
    "    point4 = (int(xsize*0.97),int(ysize))\n",
    "    #print(point4)\n",
    "    return([point1,point2,point3,point4])\n",
    "\n",
    "# define source and destination points for transform\n",
    "src = np.float32([(575,464),\n",
    "                  (707,464), \n",
    "                  (258,682), \n",
    "                  (1049,682)])\n",
    "\n",
    "undistort_test_images = glob.glob('./output_images/test*_undist.jpg')\n",
    "for idx, fname in enumerate(undistort_test_images):\n",
    "    undist_image = cv2.imread(fname)\n",
    "    h,w = undist_image.shape[:2]\n",
    "    #print(\"Height and Width:\"+str(h)+\",\"+str(w))\n",
    "    #print(\"Image Size:\"+str(undist_image[1])+\",\"+str(undist_image[0]))\n",
    "    \n",
    "    dst = np.float32([(450,0),\n",
    "                  (w-450,0),\n",
    "                  (450,h),\n",
    "                  (w-450,h)])\n",
    "    #unwarped_image, M, Minv = warp_image(undist_image, src, dst)\n",
    "    unwarped_image, M, Minv = unwarp(undist_image, src, dst)\n",
    "\n",
    "    # Visualize unwarp\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(undist_image)\n",
    "    \n",
    "    #Draw Quadrilateral on the original undistorted image for painting lanes in pipeline\n",
    "    #vertices = find_polygon(h, w)\n",
    "#     x = [vertices[0][0],vertices[2][0],vertices[3][0],vertices[1][0],vertices[0][0]]\n",
    "#     y = [vertices[0][1],vertices[2][1],vertices[3][1],vertices[1][1],vertices[0][1]]\n",
    "#     print('Vertices X:',x)\n",
    "#     print('Vertices Y:',y)    \n",
    "    x = [src[0][0],src[2][0],src[3][0],src[1][0],src[0][0]]\n",
    "    y = [src[0][1],src[2][1],src[3][1],src[1][1],src[0][1]]\n",
    "#     print('Vertices X:',x)\n",
    "#     print('Vertices Y:',y)    \n",
    "\n",
    "    #Draw Quadrilateral\n",
    "    ax1.plot(x, y, color='red', alpha=0.8, linewidth=3, solid_capstyle='round', zorder=2)\n",
    "    ax1.set_ylim([h,0])\n",
    "    ax1.set_xlim([0,w])\n",
    "    ax1.set_title('Undistorted Image', fontsize=30)\n",
    "    ax2.imshow(unwarped_image)\n",
    "    ax2.set_title('Unwarped Image', fontsize=30)\n",
    "    cv2.imwrite('./output_images/warp/test_unwarp'+str(idx)+'.jpg', unwarped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Explore Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unwarp_image_check = cv2.imread('./output_images/warp/test_unwarp0.jpg')\n",
    "# Explore RGB Color Channels\n",
    "unwarp_image_check_R = unwarp_image_check[:,:,0]\n",
    "unwarp_image_check_G = unwarp_image_check[:,:,1]\n",
    "unwarp_image_check_B = unwarp_image_check[:,:,2]\n",
    "\n",
    "#Explore HSV channel\n",
    "unwarp_image_check_HSV = cv2.cvtColor(unwarp_image_check, cv2.COLOR_RGB2HSV)\n",
    "unwarp_image_check_H   = unwarp_image_check_HSV[:,:,0]\n",
    "unwarp_image_check_S   = unwarp_image_check_HSV[:,:,1]\n",
    "unwarp_image_check_V   = unwarp_image_check_HSV[:,:,2]\n",
    "\n",
    "#Explore Lab Channel\n",
    "unwarp_image_check_LAB = cv2.cvtColor(unwarp_image_check, cv2.COLOR_RGB2Lab)\n",
    "unwarp_image_check_L   = unwarp_image_check_LAB[:,:,0]\n",
    "unwarp_image_check_A   = unwarp_image_check_LAB[:,:,1]\n",
    "unwarp_image_check_B2  = unwarp_image_check_LAB[:,:,2]\n",
    "\n",
    "fig, axs = plt.subplots(3,3, figsize=(20,10))\n",
    "fig.subplots_adjust(hspace = .2, wspace=.02)\n",
    "axs = axs.ravel()\n",
    "axs[0].imshow(unwarp_image_check_R, cmap='gray')\n",
    "axs[0].set_title('R-channel', fontsize=30)\n",
    "axs[1].imshow(unwarp_image_check_G, cmap='gray')\n",
    "axs[1].set_title('G-Channel', fontsize=30)\n",
    "axs[2].imshow(unwarp_image_check_B, cmap='gray')\n",
    "axs[2].set_title('B-channel', fontsize=30)\n",
    "axs[3].imshow(unwarp_image_check_H, cmap='gray')\n",
    "axs[3].set_title('H-Channel', fontsize=30)\n",
    "axs[4].imshow(unwarp_image_check_S, cmap='gray')\n",
    "axs[4].set_title('S-channel', fontsize=30)\n",
    "axs[5].imshow(unwarp_image_check_V, cmap='gray')\n",
    "axs[5].set_title('V-Channel', fontsize=30)\n",
    "axs[6].imshow(unwarp_image_check_L, cmap='gray')\n",
    "axs[6].set_title('L-channel', fontsize=30)\n",
    "axs[7].imshow(unwarp_image_check_A, cmap='gray')\n",
    "axs[7].set_title('A-Channel', fontsize=30)\n",
    "axs[8].imshow(unwarp_image_check_B2, cmap='gray')\n",
    "axs[8].set_title('B-Channel', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 Testing thresholds - Absolute, Magnitude, Direction and Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', kernel_size=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) #Convert to gray scale\n",
    "    #Call Sobel filter based on the orientation\n",
    "    if orient == 'x': \n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    #Get the absolute value of Sobel filter\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(abs_sobel / np.max(abs_sobel) * 255)\n",
    "    abs_threshold = np.zeros_like(scaled_sobel)\n",
    "    abs_threshold[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return abs_threshold\n",
    "\n",
    "\n",
    "def mag_thresh(img, kernel_size=3, mag_thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gradx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    grady = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    magnitude = np.sqrt(np.power(gradx, 2) + np.power(grady, 2))\n",
    "    scaled_magnitude = np.uint8(255 * magnitude / np.max(magnitude))\n",
    "    magnitude_threshold = np.zeros_like(scaled_magnitude)\n",
    "    magnitude_threshold[(scaled_magnitude > mag_thresh[0]) & (scaled_magnitude < mag_thresh[1])] = 1\n",
    "    return magnitude_threshold\n",
    "\n",
    "\n",
    "def dir_threshold(img, kernel_size=3, thresh=(0, np.pi / 2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gradx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    grady = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    abs_x = np.abs(gradx)\n",
    "    abs_y = np.abs(grady)\n",
    "    direction_threshold = np.arctan2(abs_y, abs_x)\n",
    "    binary_output = np.zeros_like(direction_threshold)\n",
    "    binary_output[(direction_threshold >= thresh[0]) & (direction_threshold <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def hls_select(image, thresh=(90, 255)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    S = hsv[:, :, 2]\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def lab_select(image, thresh=(90, 255)):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    B = lab[:, :, 2]\n",
    "    binary = np.zeros_like(B)\n",
    "    binary[(B > thresh[0]) & (B <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def combined(image):\n",
    "    ksize = 3\n",
    "    s_thresh = hls_select(image, thresh=(100, 255))\n",
    "    b_thresh = lab_select(image, thresh=(190, 255))\n",
    "\n",
    "    gradx = abs_sobel_thresh(image, orient='x', kernel_size=ksize, thresh=(15, 210))\n",
    "    grady = abs_sobel_thresh(image, orient='y', kernel_size=ksize, thresh=(15, 210))\n",
    "    dir_binary = dir_threshold(image, kernel_size=15, thresh=(0.7, 1.2))\n",
    "    mag_binary = mag_thresh(image, kernel_size=9, mag_thresh=(50, 200))\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | (s_thresh == 1) | (b_thresh == 1)] = 1\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Absolute Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unwarped_test_images = glob.glob('./output_images/warp/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(unwarped_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    unwarp_image = cv2.imread(fname)\n",
    "    grad_binary_x = abs_sobel_thresh(unwarp_image, orient='x', kernel_size=3, thresh=(15, 210))\n",
    "    grad_binary_y = abs_sobel_thresh(unwarp_image, orient='y', kernel_size=3, thresh=(15, 210))\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    ax1.imshow(unwarp_image)\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(grad_binary_x, cmap='gray')\n",
    "    ax2.set_title('X Absolute Gradient', fontsize=30)\n",
    "    ax3.imshow(grad_binary_y, cmap='gray')\n",
    "    ax3.set_title('Y Absolute Gradient', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sobel Magnitude Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(unwarped_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    unwarp_image = cv2.imread(fname)\n",
    "    mag_binary = mag_thresh(unwarp_image, kernel_size=9, mag_thresh=(50, 200))\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(unwarp_image)\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(mag_binary, cmap='gray')\n",
    "    ax2.set_title('Magnitude Thresholded Gradient', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Direction Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(unwarped_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    unwarp_image = cv2.imread(fname)\n",
    "    dir_binary = dir_threshold(unwarp_image, kernel_size=15, thresh=(0.7, 1.3))\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(unwarp_image)\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(dir_binary, cmap='gray')\n",
    "    ax2.set_title('Direction Thresholded Gradient', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Color S Channel Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(unwarped_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    unwarp_image = cv2.imread(fname)\n",
    "    hls_binary = hls_select(unwarp_image, thresh=(100, 255))\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(unwarp_image)\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(hls_binary, cmap='gray')\n",
    "    ax2.set_title('S Channel Gradient', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Color B Channel Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Surprised to find that the B Channel covering Blue-Yellow in LAB color space detects yellow lanes very well after adjusting thresholds\n",
    "for idx, fname in enumerate(unwarped_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    unwarp_image = cv2.imread(fname)\n",
    "    lab_binary = lab_select(unwarp_image, thresh=(190, 255))\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(unwarp_image)\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(lab_binary, cmap='gray')\n",
    "    ax2.set_title('B Channel Gradient', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Combined Binary Image Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined(image):\n",
    "    ksize = 3\n",
    "    s_thresh = hls_select(image, thresh=(100, 255))\n",
    "    b_thresh = lab_select(image, thresh=(190, 255))\n",
    "\n",
    "    gradx = abs_sobel_thresh(image, orient='x', kernel_size=ksize, thresh=(15, 210))\n",
    "    grady = abs_sobel_thresh(image, orient='y', kernel_size=ksize, thresh=(15, 210))\n",
    "    dir_binary = dir_threshold(image, kernel_size=15, thresh=(0.7, 1.2))\n",
    "    mag_binary = mag_thresh(image, kernel_size=9, mag_thresh=(50, 200))\n",
    "    #combined = np.dstack((np.zeros_like(dir_binary), mag_binary, grady, gradx, s_thresh, b_thresh))\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | (s_thresh == 1) | (b_thresh == 1)] = 1\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(unwarped_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    unwarp_image = cv2.imread(fname)\n",
    "    combined_binary = combined(unwarp_image)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(unwarp_image)\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(combined_binary, cmap='gray')\n",
    "    ax2.set_title('Combined Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Test - Putting it all together - Undistort, Unwarp and Combined Threshold Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(input_image):\n",
    "    #img = undistort_image(input_image)\n",
    "    img = undistort(input_image)\n",
    "    img, M, Minv = unwarp(img, src, dst)\n",
    "    img = combined(img)\n",
    "    return img\n",
    "\n",
    "# Make a list of example images\n",
    "starting_test_images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(starting_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    input_image = cv2.imread(fname)\n",
    "    result = pipeline(input_image)\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax1.imshow(input_image, cmap='gray')\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(result, cmap='gray')\n",
    "    ax2.set_title('Pipeline Result', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 8 Draw Histogram to identify lanes and Fit Polynomial to Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define method to fit polynomial AX**2+BX+C to binary image with lines extracted, using sliding window\n",
    "def orchestrate_sliding_windows(img):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    quarter_point = np.int(midpoint//2)\n",
    "    # Previously the left/right base was the max of the left/right half of the histogram\n",
    "    # this changes it so that only a quarter of the histogram (directly to the left/right) is considered\n",
    "    leftx_base = np.argmax(histogram[quarter_point:midpoint]) + quarter_point\n",
    "    rightx_base = np.argmax(histogram[midpoint:(midpoint+quarter_point)]) + midpoint\n",
    "    \n",
    "    #print('base pts:', leftx_base, rightx_base)\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 10\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 40\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Rectangle data for visualization\n",
    "    rectangle_data = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        rectangle_data.append((win_y_low, win_y_high, win_xleft_low, win_xleft_high, win_xright_low, win_xright_high))\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    left_fit, right_fit = (None, None)\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(leftx) != 0:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    visualization_data = (rectangle_data, histogram)\n",
    "    \n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sliding Window Orchestration and Polyomial Fit with All Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(starting_test_images):\n",
    "    # Run the Absolute Threshold function\n",
    "    input_image = cv2.imread(fname)\n",
    "    result = pipeline(input_image)\n",
    "    left_fit, right_fit, left_lane_inds, right_lane_inds, visualization_data = orchestrate_sliding_windows(result)\n",
    "    h, w = result.shape[1], result.shape[0]\n",
    "    \n",
    "    #Fit X-intercepts\n",
    "    left_fit_x_int = left_fit[0]*h**2 + left_fit[1]*h + left_fit[2]\n",
    "    right_fit_x_int = right_fit[0]*h**2 + right_fit[1]*h + right_fit[2]\n",
    "    \n",
    "    rectangles = visualization_data[0]\n",
    "    histogram = visualization_data[1]\n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.uint8(np.dstack((result, result, result))*255)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, result.shape[0]-1, result.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Draw the rectangle windows on the visualization image    \n",
    "    for rect in rectangles:\n",
    "        cv2.rectangle(out_img,(rect[2],rect[0]),(rect[3],rect[1]),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(rect[4],rect[0]),(rect[5],rect[1]),(0,255,0), 2) \n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = result.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [100, 200, 255]\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    \n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax1.imshow(result, cmap='gray')\n",
    "    ax1.set_title('Pipeline Image', fontsize=30)\n",
    "    ax2.imshow(out_img, cmap='gray')\n",
    "    ax2.set_title('Polynomial Fit', fontsize=30)\n",
    "    ax3.imshow(input_image, cmap='gray')\n",
    "    ax3.set_title('Original Image', fontsize=30)\n",
    "    plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radius of Curvature, Lane Width and Positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
